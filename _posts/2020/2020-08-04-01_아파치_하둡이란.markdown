---
layout: post
title: "bigdata_computing 01.아파치_하둡이란"
date: 2020-08-04 19:20:23 +0900
category: lecture
---

# 1강 아파치 하둡이란

빅데이터처리에서는 내용을 잘 공개하지 않음

> 빅데이터를 저장, 처리, 분석할 수 있는 소프트웨어 프레임 워크

```
Distributed : 수십만대의 컴퓨터에 자료 분산 저장 및 처리
Scalable : 용량이 증대되는 대로 컴퓨터 추가
Fault-tolerant : 하나이상의 컴퓨터가 고장나는 경우에도 시스템이 정상 동작
Open source : 공개 소프트웨어
```

> 에코시스템

```
소프트웨어가 발전하기 위해 비슷한 여러 시스템이 생셩되는 현상
```

> 하둡을 시작하게된 동기 

```
google이 2000년도 초반에서 먼저 시작

너무 많은 웹페이지를 처리할 수 가 없어서 생각하게됨 

처음에는 GFS(Google File System) 과 MapReduce를 제안하게 됨 (소스는 비공개로 오픈)

아파치 제단에서 위를 분석해서 만든게 하둡(Hadoop) 공개 소프트웨어를 만듦

history
구글에서 돈이 부족하여 IBM 성능을 따라잡기 위해 저 예산 PC를 사서 묶어서 만듦

야후의 많은 엔지니어들이 아파치그룹에서 함께 만들어나감 
```

> 분산시스템의 진화

```
하나의 작어베 여러 대의 machine을 사용
MPI(Message Passing Interfae) -> 매우 복잡
```